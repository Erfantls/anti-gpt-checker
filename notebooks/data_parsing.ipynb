{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-12T00:06:12.480523300Z",
     "start_time": "2024-01-12T00:06:11.817434900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dao.email import DAOEmail, DAOEmailGmail\n",
    "from models.email import Email, EmailGithubDataset\n",
    "from dateutil import parser as date_parser\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  spam\n",
      "0  Subject: naturally irresistible your corporate...     1\n",
      "1  Subject: the stock trading gunslinger  fanny i...     1\n",
      "2  Subject: unbelievable new homes made easy  im ...     1\n",
      "3  Subject: 4 color printing special  request add...     1\n",
      "4  Subject: do not have money , get software cds ...     1\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/Email/English/raw/spam_email_dataset/emails.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T14:21:49.491602400Z",
     "start_time": "2024-01-02T14:21:49.399343700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions and the information isoverwhelminq ; but a good  catchy logo , stylish statlonery and outstanding website  will make the task much easier .  we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader : it isguite ciear that  without good products , effective business organization and practicable aim it  will be hotat nowadays market ; but we do promise that your marketing efforts  will become much more effective . here is the list of clear  benefits : creativeness : hand - made , original logos , specially done  to reflect your distinctive company image . convenience : logo and stationery  are provided in all formats ; easy - to - use content management system letsyou  change your website content and even its structure . promptness : you  will see logo drafts within three business days . affordability : your  marketing break - through shouldn ' t make gaps in your budget . 100 % satisfaction  guaranteed : we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration . have a look at our  portfolio _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ not interested . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "# get first entry from df\n",
    "print(df.iloc[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T14:21:49.496599600Z",
     "start_time": "2024-01-02T14:21:49.491071100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dao = DAOEmail(\"email_spam_dataset\")\n",
    "\n",
    "# iterate row by row\n",
    "for index, row in df.iterrows():\n",
    "    splitted = row.text.split(\"  \")\n",
    "    subject = splitted[0].replace(\"Subject: \", \"\")\n",
    "    body = \" \".join(splitted[1:])\n",
    "    is_spam = (int(row.spam) == 1)\n",
    "    email = Email(subject=subject, body=body, is_html=False, is_spam=is_spam)\n",
    "    dao.insert_one(email)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T14:23:19.601676Z",
     "start_time": "2024-01-02T14:23:15.688162600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from models.email import EmailGithubDataset, GithubClassEnums\n",
    "from email import message_from_file\n",
    "\n",
    "\n",
    "def parse_email(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        msg = message_from_file(file)\n",
    "\n",
    "        from_address = msg.get('From')\n",
    "        to_address = msg.get('To')\n",
    "        date_str = msg.get('Date')\n",
    "        date = None\n",
    "        if date_str:\n",
    "            date = date_parser.parse(date_str)\n",
    "\n",
    "\n",
    "        subject = msg.get('Subject')\n",
    "\n",
    "\n",
    "        body = \"\"\n",
    "        is_html = False\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                body += part.get_payload()\n",
    "            elif part.get_content_type() == 'text/html':\n",
    "                body += part.get_payload()\n",
    "                is_html = True\n",
    "\n",
    "        return EmailGithubDataset(\n",
    "            from_address=from_address,\n",
    "            to_address=to_address,\n",
    "            date=date,\n",
    "            subject=subject,\n",
    "            body=body,\n",
    "            is_html=is_html,\n",
    "            is_spam=None,  # Set this based on your spam detection logic\n",
    "            is_ai_generated=None,  # Set this based on your AI generation detection logic\n",
    "            inner_classification=GithubClassEnums.CALENDAR.value\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T21:45:39.024603300Z",
     "start_time": "2024-01-02T21:45:39.018860700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "folder_path = \"../data/Email/English/raw/Email-Classification-github/dataset/calendar\"\n",
    "dao = DAOEmail(\"email_classification_github\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.isnumeric():\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        email_data = parse_email(file_path)\n",
    "        dao.insert_one(email_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T14:10:28.948612Z",
     "start_time": "2024-01-02T14:10:28.831444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n",
      "1  From gort44@excite.com Mon Jun 24 17:54:21 200...       1\n",
      "2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1\n",
      "3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1\n",
      "4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/Email/English/raw/email_classification_dataset/spam_assassin.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:48:27.811779500Z",
     "start_time": "2024-01-02T17:48:27.541490100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ilug-admin@linux.ie Mon Jul 29 11:28:02 2002 Return-Path: <ilug-admin@linux.ie> Delivered-To: yyyy@localhost.netnoteinc.com Received: from localhost (localhost [127.0.0.1]) by phobos.labs.netnoteinc.com (Postfix) with ESMTP id A13D94414F for <jm@localhost>; Mon, 29 Jul 2002 06:25:11 -0400 (EDT) Received: from phobos [127.0.0.1] by localhost with IMAP (fetchmail-5.9.0) for jm@localhost (single-drop); Mon, 29 Jul 2002 11:25:11 +0100 (IST) Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g6RHn7i17130 for <jm-ilug@jmason.org>; Sat, 27 Jul 2002 18:49:07 +0100 Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA25016; Sat, 27 Jul 2002 18:45:03 +0100 X-Authentication-Warning: lugh.tuatha.org: Host root@localhost [127.0.0.1] claimed to be lugh Received: from mail1.mail.iol.ie (mail1.mail.iol.ie [194.125.2.192]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA24977 for <ilug@linux.ie>; Sat, 27 Jul 2002 18:44:56 +0100 Received: from dialup125-a.ts551.cwt.esat.net ([193.203.140.125] helo=Hobbiton.cod.ie) by mail1.mail.iol.ie with esmtp (Exim 3.35 #1) id 17YVVF-0001W4-00 for ilug@linux.ie; Sat, 27 Jul 2002 18:37:18 +0100 Received: (from cdaly@localhost) by Hobbiton.cod.ie (8.11.6/8.9.3) id g6RDRoO04681 for ilug@linux.ie; Sat, 27 Jul 2002 14:27:50 +0100 Date: Sat, 27 Jul 2002 14:27:49 +0100 From: Conor Daly <conor.daly@oceanfree.net> To: ILUG main list <ilug@linux.ie> Subject: Re: [ILUG] Architecture crossover trouble w RH7.2 (solved) Message-Id: <20020727142749.B4438@Hobbiton.cod.ie> Mail-Followup-To: ILUG main list <ilug@linux.ie> References: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com> MIME-Version: 1.0 Content-Type: text/plain; charset=us-ascii Content-Disposition: inline User-Agent: Mutt/1.2.5i In-Reply-To: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com>; from conor_wynne@maxtor.com on Fri, Jul 26, 2002 at 03:56:22PM +0100 Sender: ilug-admin@linux.ie Errors-To: ilug-admin@linux.ie X-Mailman-Version: 1.1 Precedence: bulk List-Id: Irish Linux Users' Group <ilug.linux.ie> X-Beenthere: ilug@linux.ie On Fri, Jul 26, 2002 at 03:56:22PM +0100 or so it is rumoured hereabouts, Wynne, Conor thought: > Surely it would be faster to save you conf files, install it on the box > again, copy back you confs and voila. > All you car about are the confs as the boite has no DATA right? Yeah, but then I'd have to remember _exactly_ which confs I'd modified and they're not all in /etc either... > Thats what I would do, but you sysadmins have to make life as difficult & > complicated as possible ;--) Yup... In this case, I had two issues. 1. I mirrored the disk to give to someone else to work on but the box he has available has only a P1 or P2 processor. 2. My celeron box has been crashing the backup software so I wanted to try out the backup in a different box to make sure it's hardware related. Again, it's also an interesting exercise... > Have you thought about mirroring the system drives? Might save you serious > hassle down the line. Oh, I'm doing that too. This is going to Africa so I'm aiming for as robust as possible with belt, braces and probably an all-in-one jumpsuit! I'll be mirroring the disk but that is worth only so much (eg. lightning strike taking out the disk(s) or system compromise) I'm also going for a backup to CDR with an automated restore http://www.mondorescue.org . The admin out there wouldn't be able to build the system again if the mobo got fried and the replacement was the wrong arch but an i386 compatible install will mean just dropping in the HD and booting (ish)... Conor -- Conor Daly <conor.daly@oceanfree.net> Domestic Sysadmin :-) --------------------- Faenor.cod.ie 2:32pm up 64 days, 23:49, 0 users, load average: 0.00, 0.00, 0.00 Hobbiton.cod.ie 2:19pm up 7 days, 20:56, 1 user, load average: 0.05, 0.02, 0.00 -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0].text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:45:59.520394300Z",
     "start_time": "2024-01-02T17:45:59.492425800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_email2(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        email_data = file.read()\n",
    "        # Regular expressions to extract information\n",
    "    from_pattern = re.compile(r'From [\\w\\-\\.]+@([\\w\\-]+\\.)+[\\w\\-]{2,4}')\n",
    "    to_pattern = re.compile(r'Delivered-To: [\\w\\-\\.]+@([\\w\\-]+\\.)+[\\w\\-]{2,4}')\n",
    "    date_pattern = re.compile(r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{1,2}\\s\\d{2}:\\d{2}:\\d{2}\\s\\d{4}\\b')\n",
    "    subject_pattern = re.compile(r'Subject: (.+)')\n",
    "    content_type = re.compile(r'Content-Type: .+?(?=;)')\n",
    "\n",
    "    # Extracting information using regular expressions\n",
    "    from_match = from_pattern.search(email_data)\n",
    "    to_match = to_pattern.search(email_data)\n",
    "    date_match = date_pattern.search(email_data)\n",
    "    subject_match = subject_pattern.search(email_data)\n",
    "\n",
    "    subject = subject_match.group(0).replace(\"Subject: \", \"\") if subject_match else None\n",
    "    if subject:\n",
    "        digit_deleted = False\n",
    "        while subject[-1].isnumeric() or (subject[-1] == \".\" and digit_deleted): # Remove trailing numbers and dots\n",
    "            subject = subject[:-1]\n",
    "            digit_deleted = True\n",
    "\n",
    "        subject = subject.strip()\n",
    "\n",
    "\n",
    "    content_type_match = content_type.search(email_data)\n",
    "    if content_type_match:\n",
    "        is_html = (\"text/html\" in content_type_match.group(0))\n",
    "    else:\n",
    "        is_html = False\n",
    "\n",
    "    lines = email_data.split(\"\\n\")\n",
    "    body_flag = False\n",
    "    body_content = \"\"\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"\" and not body_flag:\n",
    "            body_flag = True\n",
    "        elif body_flag:\n",
    "            body_content += (line + \"\\n\")\n",
    "\n",
    "    # Creating the EmailBase instance\n",
    "    email_instance = Email(\n",
    "        from_address=from_match.group(0).replace(\"From \", \"\") if from_match else None,\n",
    "        to_address=to_match.group(0).replace(\"Delivered-To: \", \"\") if to_match else None,\n",
    "        date=datetime.strptime(date_match.group(0), \"%b %d %H:%M:%S %Y\") if date_match else None,\n",
    "        subject=subject,\n",
    "        body=body_content,\n",
    "        is_html=is_html,  # You may need to implement HTML detection logic\n",
    "        is_spam=None,   # You may need to implement spam detection logic\n",
    "        is_ai_generated=None  # You may need to implement AI-generated detection logic\n",
    "    )\n",
    "\n",
    "    return email_instance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T22:26:45.522104100Z",
     "start_time": "2024-01-02T22:26:45.518387200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "folder_path = \"../data/Email/English/raw/email_classification_dataset/2005spam_2\"\n",
    "dao = DAOEmail(\"email_spam_assassin_dataset\")\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.split(\".\")[0].isnumeric():\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        email_data = parse_email2(file_path)\n",
    "        email_data.is_spam = True\n",
    "        dao.insert_one(email_data)\n",
    "    # dao.insert_one(email_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T23:54:59.384276400Z",
     "start_time": "2024-01-02T23:54:56.993557500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n",
      "Document too large\n"
     ]
    }
   ],
   "source": [
    "from pymongo.errors import DocumentTooLarge\n",
    "from analysis.mbox_reader import GmailMboxMessage\n",
    "import mailbox\n",
    "\n",
    "mbox_obj_gmail1 = mailbox.mbox('../data/Email/Personal/gmail1.mbox')\n",
    "# mbox_obj_gmail2 = mailbox.mbox('../data/Email/Personal/gmail2.mbox')\n",
    "# mbox_obj_gmail3 = mailbox.mbox('../data/Email/Personal/gmail3.mbox')\n",
    "\n",
    "\n",
    "dao_gmail1 = DAOEmail(\"gmail1\")\n",
    "# dao_gmail2 = DAOEmail(\"gmail2\")\n",
    "# dao_gmail3 = DAOEmail(\"gmail3\")\n",
    "counter1= 0\n",
    "# counter2= 0\n",
    "# counter3= 0\n",
    "# for idx, email_obj in enumerate(mbox_obj_gmail2):\n",
    "#     email_data = GmailMboxMessage(email_obj)\n",
    "#     gmail_model = email_data.parse_to_email_model()\n",
    "#     try:\n",
    "#         dao_gmail2.insert_one(gmail_model)\n",
    "#     except UnicodeEncodeError:\n",
    "#         counter2 += 1\n",
    "#\n",
    "# print(counter2)\n",
    "#\n",
    "# for idx, email_obj in enumerate(mbox_obj_gmail3):\n",
    "#     email_data = GmailMboxMessage(email_obj)\n",
    "#     gmail_model = email_data.parse_to_email_model()\n",
    "#     try:\n",
    "#         dao_gmail3.insert_one(gmail_model)\n",
    "#     except UnicodeEncodeError:\n",
    "#         counter3 += 1\n",
    "#\n",
    "# print(counter3)\n",
    "for idx, email_obj in enumerate(mbox_obj_gmail1):\n",
    "    email_data = GmailMboxMessage(email_obj)\n",
    "    try:\n",
    "        gmail_model = email_data.parse_to_email_model()\n",
    "    except:\n",
    "        counter1 += 1\n",
    "        continue\n",
    "    try:\n",
    "        dao_gmail1.insert_one(gmail_model)\n",
    "    except UnicodeEncodeError:\n",
    "        counter1 += 1\n",
    "    except DocumentTooLarge:\n",
    "        counter1 += 1\n",
    "        print(\"Document too large\")\n",
    "\n",
    "print(counter1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-11T02:01:50.121774100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m emails \u001B[38;5;241m=\u001B[39m dao\u001B[38;5;241m.\u001B[39mfind_all()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m email \u001B[38;5;129;01min\u001B[39;00m emails:\n\u001B[1;32m----> 7\u001B[0m     ext \u001B[38;5;241m=\u001B[39m \u001B[43mextract_strings_from_html\u001B[49m\u001B[43m(\u001B[49m\u001B[43memail\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     detected_lang \u001B[38;5;241m=\u001B[39m detect_language(ext)\n\u001B[0;32m      9\u001B[0m     dao\u001B[38;5;241m.\u001B[39mupdate_one({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_id\u001B[39m\u001B[38;5;124m\"\u001B[39m:email\u001B[38;5;241m.\u001B[39mid}, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$set\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdetected_lang\u001B[39m\u001B[38;5;124m\"\u001B[39m: detected_lang}})\n",
      "File \u001B[1;32mD:\\Dev\\Github\\anti-gpt-checker\\analysis\\attribute_retriving.py:190\u001B[0m, in \u001B[0;36mextract_strings_from_html\u001B[1;34m(html_text, ignore_links)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;124;03mExtract text strings from HTML.\u001B[39;00m\n\u001B[0;32m    182\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;124;03m- str with concatenated text strings.\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    189\u001B[0m html2text_handler\u001B[38;5;241m.\u001B[39mignore_links \u001B[38;5;241m=\u001B[39m ignore_links\n\u001B[1;32m--> 190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhtml2text_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhtml_text\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Dev\\Github\\anti-gpt-checker\\venv\\Lib\\site-packages\\html2text\\__init__.py:142\u001B[0m, in \u001B[0;36mHTML2Text.handle\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandle\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m--> 142\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeed(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    144\u001B[0m     markdown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptwrap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinish())\n",
      "File \u001B[1;32mD:\\Dev\\Github\\anti-gpt-checker\\venv\\Lib\\site-packages\\html2text\\__init__.py:138\u001B[0m, in \u001B[0;36mHTML2Text.feed\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 138\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m + \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscript>\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m</ignore>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfeed(data)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "from analysis.attribute_retriving import extract_strings_from_html, detect_language\n",
    "\n",
    "daos = [DAOEmailGmail(\"gmail1\"), DAOEmailGmail(\"gmail2\"), DAOEmailGmail(\"gmail3\")]\n",
    "for dao in daos:\n",
    "    emails = dao.find_all()\n",
    "    for email in emails:\n",
    "        ext = extract_strings_from_html(email.body)\n",
    "        detected_lang = detect_language(ext)\n",
    "        dao.update_one({\"_id\":email.id}, {\"$set\": {\"detected_lang\": detected_lang}})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T00:08:19.715573200Z",
     "start_time": "2024-01-12T00:08:13.710519200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

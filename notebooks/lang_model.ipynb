{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:52:11.978653800Z",
     "start_time": "2024-02-19T08:52:01.676918100Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from dao.email import AVAILABLE_EMAIL_DAOS\n",
    "from analysis.attribute_statistics import SimpleLanguageStatistics\n",
    "from analysis.nlp_transformations import lemmatize_text\n",
    "from config import init_spacy_english_nlp_model, init_spacy_polish_nlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/.virtualenvs/anti-gpt-checker/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/pawel/.virtualenvs/anti-gpt-checker/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "init_spacy_english_nlp_model()\n",
    "init_spacy_polish_nlp_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:52:22.801348100Z",
     "start_time": "2024-02-19T08:52:13.307393200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dao = AVAILABLE_EMAIL_DAOS['spam_assassin']\n",
    "query = {'body': {'$regex': \"<body>\"}, 'is_html': False}\n",
    "docs = dao.find_many_by_query(query)\n",
    "for doc in docs:\n",
    "    dao.update_one({'_id': doc.id}, {'$set': {'is_html': True}})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:30:46.979092900Z",
     "start_time": "2024-02-19T08:30:46.861120200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_spam_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing texts: 0emails [00:00, ?emails/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_classification_github\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing texts: 0emails [00:00, ?emails/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_spam_assassin_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatizing texts: 100%|██████████| 7440/7440 [2:52:31<00:00,  1.39s/emails]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing texts: 100%|██████████| 31836/31836 [1:33:53<00:00,  5.65emails/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing texts: 100%|██████████| 2817/2817 [33:43<00:00,  1.39emails/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing texts: 100%|██████████| 4123/4123 [23:57<00:00,  2.87emails/s]  \n"
     ]
    }
   ],
   "source": [
    "for dao_name in AVAILABLE_EMAIL_DAOS:\n",
    "    dao = AVAILABLE_EMAIL_DAOS[dao_name]\n",
    "    print(dao.collection_name)\n",
    "    query = {'lemmatized_subject':{'$exists': False}}\n",
    "    documents = dao.find_many_by_query(query)\n",
    "    total_documents = len(documents)\n",
    "    for doc in tqdm(documents, total=total_documents, desc='Lemmatizing texts', unit='emails', miniters=1):\n",
    "        if doc.is_html:\n",
    "            if doc.text_plain:\n",
    "                body = doc.text_plain\n",
    "            else:\n",
    "                body = \"\"\n",
    "        else:\n",
    "            if doc.text_plain:\n",
    "                body = doc.text_plain\n",
    "            else:\n",
    "                body = doc.body\n",
    "\n",
    "        if doc.detected_language == 'pl' or doc.detected_language == 'en':\n",
    "            lang = doc.detected_language\n",
    "        else:\n",
    "            continue # skip non-english and non-polish emails\n",
    "\n",
    "        if body == \"\":\n",
    "            lem_body_str = \"\"\n",
    "        else:\n",
    "            lem_body_str, _ = lemmatize_text(text=body, lang_code=lang)\n",
    "\n",
    "\n",
    "        lem_subject_str, _ = lemmatize_text(text=doc.subject, lang_code=lang)\n",
    "        dao.update_one({'_id': doc.id}, {'$set': {'lemmatized_subject': lem_subject_str,\n",
    "          'lemmatized_body': lem_body_str}})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T14:36:58.185974400Z",
     "start_time": "2024-02-19T09:12:42.897371500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "language_models = {}\n",
    "chunk_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:37:22.766103200Z",
     "start_time": "2024-02-19T20:37:22.743160600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing email texts from email_spam_dataset:   0%|          | 0/5728 [00:36<?, ?emails/s]\u001B[A\n",
      "\n",
      "Processing email texts from email_spam_dataset:  24%|██▍       | 1400/5728 [00:00<00:00, 12769.88emails/s]\u001B[A\n",
      "Processing email texts from email_spam_dataset:  44%|████▎     | 2500/5728 [00:00<00:00, 11724.31emails/s]\u001B[A\n",
      "Processing email texts from email_spam_dataset:  63%|██████▎   | 3600/5728 [00:00<00:00, 11221.61emails/s]\u001B[A\n",
      "Processing email texts from email_spam_dataset: 100%|██████████| 5728/5728 [00:00<00:00, 11116.75emails/s]\u001B[A\n",
      "Processing email texts from email_classification_github: 100%|██████████| 1189/1189 [00:00<00:00, 32763.26emails/s]\n",
      "Processing email texts from email_spam_assassin_dataset: 100%|██████████| 13239/13239 [00:01<00:00, 7818.74emails/s]\n",
      "Processing email texts from gmail1: 100%|██████████| 31584/31584 [00:04<00:00, 7014.77emails/s] \n",
      "Processing email texts from gmail2: 100%|██████████| 2806/2806 [00:00<00:00, 4245.66emails/s]\n",
      "Processing email texts from gmail3: 100%|██████████| 4103/4103 [00:01<00:00, 2770.17emails/s]\n"
     ]
    }
   ],
   "source": [
    "for dao_name in AVAILABLE_EMAIL_DAOS:\n",
    "    dao = AVAILABLE_EMAIL_DAOS[dao_name]\n",
    "    query = {'$or':[{'detected_language': 'en'},{'detected_language': 'pl'}]}\n",
    "    total_documents = dao.collection.count_documents(query)\n",
    "    progress_bar = tqdm(total=total_documents, desc=f\"Processing email texts from {dao.collection_name}\", unit=\"emails\",\n",
    "                        miniters=1)\n",
    "    cursor = dao.collection.find(query).batch_size(chunk_size)\n",
    "    try:\n",
    "        documents_processed = 0\n",
    "        while documents_processed < total_documents:\n",
    "            documents = list(cursor.next() for _ in range(min(chunk_size, total_documents - documents_processed)))\n",
    "            for doc in documents:\n",
    "                text = doc['lemmatized_body'] +\" \"+ doc['lemmatized_subject']\n",
    "                lang = doc['detected_language']\n",
    "                if lang not in language_models:\n",
    "                    language_models[lang] = SimpleLanguageStatistics(lang)\n",
    "                language_models[lang].add_texts([text])\n",
    "\n",
    "            documents_processed += len(documents)\n",
    "            progress_bar.update(len(documents))\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "    progress_bar.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:38:10.178996200Z",
     "start_time": "2024-02-19T20:38:00.479360800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'en': <analysis.attribute_statistics.SimpleLanguageStatistics at 0x7f8d98132680>,\n 'pl': <analysis.attribute_statistics.SimpleLanguageStatistics at 0x7f8d48b36080>}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:38:17.374564500Z",
     "start_time": "2024-02-19T20:38:17.347567200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "for lang in language_models:\n",
    "    language_models[lang].save_to_file(f'../data/simple_language_models/{lang}_lang_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:49:01.431000100Z",
     "start_time": "2024-02-19T20:49:01.422696400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-18T21:12:20.645756800Z",
     "start_time": "2024-02-18T21:12:18.632929300Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from dao.email import AVAILABLE_EMAIL_DAOS\n",
    "from analysis.attribute_statistics import SimpleLanguageStatistics\n",
    "from analysis.nlp_transformations import lemmatize_text\n",
    "from config import init_spacy_english_nlp_model, init_spacy_polish_nlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/.virtualenvs/anti-gpt-checker/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/pawel/.virtualenvs/anti-gpt-checker/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "init_spacy_english_nlp_model()\n",
    "init_spacy_polish_nlp_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T21:12:28.119781400Z",
     "start_time": "2024-02-18T21:12:22.232762100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email_spam_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing texts:  66%|██████▌   | 3759/5728 [27:31<09:26,  3.48emails/s]  "
     ]
    }
   ],
   "source": [
    "for dao_name in AVAILABLE_EMAIL_DAOS:\n",
    "    dao = AVAILABLE_EMAIL_DAOS[dao_name]\n",
    "    print(dao.collection_name)\n",
    "    query = {}\n",
    "    documents = dao.find_many_by_query(query)\n",
    "    total_documents = len(documents)\n",
    "    for doc in tqdm(documents, total=total_documents, desc='Lemmatizing texts', unit='emails', miniters=1):\n",
    "        if doc.is_html:\n",
    "            if doc.text_plain:\n",
    "                body = doc.text_plain\n",
    "            else:\n",
    "                body = \"\"\n",
    "        else:\n",
    "            if doc.text_plain:\n",
    "                body = doc.text_plain\n",
    "            else:\n",
    "                body = doc.body\n",
    "\n",
    "        if doc.detected_language == 'pl' or doc.detected_language == 'en':\n",
    "            lang = doc.detected_language\n",
    "        else:\n",
    "            continue # skip non-english and non-polish emails\n",
    "\n",
    "        lem_body_str, _ = lemmatize_text(text=body, lang_code=lang)\n",
    "        lem_subject_str, _ = lemmatize_text(text=doc.subject, lang_code=lang)\n",
    "        dao.update_one({'_id': doc.id}, {'$set': {'lemmatized_subject': lem_subject_str,\n",
    "          'lemmatized_body': lem_body_str}})\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-18T21:12:31.712028500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "language_models = {}\n",
    "chunk_size = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dao_name in AVAILABLE_EMAIL_DAOS:\n",
    "    dao = AVAILABLE_EMAIL_DAOS[dao_name]\n",
    "    total_documents = dao.collection.count_documents({})\n",
    "    progress_bar = tqdm(total=total_documents, desc=f\"Processing email texts from {dao.collection_name}\", unit=\"emails\",\n",
    "                        miniters=1)\n",
    "    cursor = dao.collection.find({}).batch_size(chunk_size)\n",
    "    try:\n",
    "        documents_processed = 0\n",
    "        while documents_processed < total_documents:\n",
    "            documents = list(cursor.next() for _ in range(min(chunk_size, total_documents - documents_processed)))\n",
    "            for doc in documents:\n",
    "                if 'detected_language' not in doc:\n",
    "                    detected_language = 'en'\n",
    "                else:\n",
    "                    detected_language = doc['detected_language']\n",
    "\n",
    "                if detected_language not in language_models:\n",
    "                    language_models[detected_language] = SimpleLanguageStatistics(detected_language)\n",
    "\n",
    "                if doc['is_html']:\n",
    "                    if 'text_plain' in doc:\n",
    "                        text = doc['text_plain']\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    if 'text_plain' in doc:\n",
    "                        text = doc['text_plain']\n",
    "                    else:\n",
    "                        text = doc['body']\n",
    "                language_models[detected_language].add_texts([text])\n",
    "\n",
    "            documents_processed += len(documents)\n",
    "            progress_bar.update(len(documents))\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "    progress_bar.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

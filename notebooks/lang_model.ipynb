{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:52:11.978653800Z",
     "start_time": "2024-02-19T08:52:01.676918100Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "from dao.email import AVAILABLE_EMAIL_DAOS\n",
    "from analysis.attribute_statistics import SimpleLanguageStatistics\n",
    "from analysis.nlp_transformations import lemmatize_text\n",
    "from config import init_spacy_english_nlp_model, init_spacy_polish_nlp_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "init_spacy_english_nlp_model()\n",
    "init_spacy_polish_nlp_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:52:22.801348100Z",
     "start_time": "2024-02-19T08:52:13.307393200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dao = AVAILABLE_EMAIL_DAOS['spam_assassin']\n",
    "query = {'body': {'$regex': \"<body>\"}, 'is_html': False}\n",
    "docs = dao.find_many_by_query(query)\n",
    "for doc in docs:\n",
    "    dao.update_one({'_id': doc.id}, {'$set': {'is_html': True}})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T08:30:46.979092900Z",
     "start_time": "2024-02-19T08:30:46.861120200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for dao_name in AVAILABLE_EMAIL_DAOS:\n",
    "    dao = AVAILABLE_EMAIL_DAOS[dao_name]\n",
    "    print(dao.collection_name)\n",
    "    query = {'lemmatized_subject':{'$exists': False}}\n",
    "    documents = dao.find_many_by_query(query)\n",
    "    total_documents = len(documents)\n",
    "    for doc in tqdm(documents, total=total_documents, desc='Lemmatizing texts', unit='emails', miniters=1):\n",
    "        if doc.is_html:\n",
    "            if doc.text_plain:\n",
    "                body = doc.text_plain\n",
    "            else:\n",
    "                body = \"\"\n",
    "        else:\n",
    "            if doc.text_plain:\n",
    "                body = doc.text_plain\n",
    "            else:\n",
    "                body = doc.body\n",
    "\n",
    "        if doc.detected_language == 'pl' or doc.detected_language == 'en':\n",
    "            lang = doc.detected_language\n",
    "        else:\n",
    "            continue # skip non-english and non-polish emails\n",
    "\n",
    "        if body == \"\":\n",
    "            lem_body_str = \"\"\n",
    "        else:\n",
    "            lem_body_str, _ = lemmatize_text(text=body, lang_code=lang)\n",
    "\n",
    "\n",
    "        lem_subject_str, _ = lemmatize_text(text=doc.subject, lang_code=lang)\n",
    "        dao.update_one({'_id': doc.id}, {'$set': {'lemmatized_subject': lem_subject_str,\n",
    "          'lemmatized_body': lem_body_str}})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T14:36:58.185974400Z",
     "start_time": "2024-02-19T09:12:42.897371500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "language_models = {}\n",
    "chunk_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:37:22.766103200Z",
     "start_time": "2024-02-19T20:37:22.743160600Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for dao_name in AVAILABLE_EMAIL_DAOS:\n",
    "    dao = AVAILABLE_EMAIL_DAOS[dao_name]\n",
    "    query = {'$or':[{'detected_language': 'en'},{'detected_language': 'pl'}]}\n",
    "    total_documents = dao.collection.count_documents(query)\n",
    "    progress_bar = tqdm(total=total_documents, desc=f\"Processing email texts from {dao.collection_name}\", unit=\"emails\",\n",
    "                        miniters=1)\n",
    "    cursor = dao.collection.find(query).batch_size(chunk_size)\n",
    "    try:\n",
    "        documents_processed = 0\n",
    "        while documents_processed < total_documents:\n",
    "            documents = list(cursor.next() for _ in range(min(chunk_size, total_documents - documents_processed)))\n",
    "            for doc in documents:\n",
    "                text = doc['lemmatized_body'] +\" \"+ doc['lemmatized_subject']\n",
    "                lang = doc['detected_language']\n",
    "                if lang not in language_models:\n",
    "                    language_models[lang] = SimpleLanguageStatistics(lang)\n",
    "                language_models[lang].add_texts([text])\n",
    "\n",
    "            documents_processed += len(documents)\n",
    "            progress_bar.update(len(documents))\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "    progress_bar.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:38:10.178996200Z",
     "start_time": "2024-02-19T20:38:00.479360800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "language_models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:38:17.374564500Z",
     "start_time": "2024-02-19T20:38:17.347567200Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for lang in language_models:\n",
    "    language_models[lang].save_to_file(f'../data/simple_language_models/{lang}_lang_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T20:49:01.431000100Z",
     "start_time": "2024-02-19T20:49:01.422696400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
